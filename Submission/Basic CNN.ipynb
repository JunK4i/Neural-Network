{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e18be072",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from tqdm.notebook import tqdm\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fae0898a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../partitioned.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_id</th>\n",
       "      <th>Gender</th>\n",
       "      <th>partition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39087</th>\n",
       "      <td>039088.jpg</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30893</th>\n",
       "      <td>030894.jpg</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45278</th>\n",
       "      <td>045279.jpg</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16398</th>\n",
       "      <td>016399.jpg</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13653</th>\n",
       "      <td>013654.jpg</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         image_id  Gender  partition\n",
       "39087  039088.jpg  Female          0\n",
       "30893  030894.jpg    Male          0\n",
       "45278  045279.jpg  Female          0\n",
       "16398  016399.jpg  Female          0\n",
       "13653  013654.jpg    Male          0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load the Dataset\n",
    "\n",
    "CELEBA_DATA_PATH = './'\n",
    "IMG_PATH = os.path.join(CELEBA_DATA_PATH, 'img_align_celeba')\n",
    "CROPPED_IMG_PATH = os.path.join(CELEBA_DATA_PATH, 'processed_img')\n",
    "\n",
    "ATTR_PATH = os.path.join(CELEBA_DATA_PATH,'list_attr_celeba.csv')\n",
    "\n",
    "\n",
    "def getImagePath(image_id):\n",
    "    return os.path.join(IMG_PATH,image_id)\n",
    "\n",
    "def getCroppedPath(image_id):\n",
    "    return os.path.join(CROPPED_IMG_PATH,image_id)\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the attributes\n",
    "attributes_df = pd.read_csv(ATTR_PATH)\n",
    "attributes_df['Gender'] = attributes_df['Male'].map({1: 'Male', -1: 'Female'})\n",
    "attributes_df['Age'] = attributes_df['Young'].map({1: 'Young', -1: 'Old'})\n",
    "attributes_df = attributes_df[['image_id', 'Gender']]\n",
    "\n",
    "# Get first 50k\n",
    "cropped_images_df = attributes_df.head(50000)\n",
    "\n",
    "# Split the data into training and validation sets \n",
    "train_df, val_test_df = train_test_split(cropped_images_df, test_size=0.2, random_state=42)\n",
    "val_df, test_df = train_test_split(val_test_df, test_size=0.5, random_state=42)\n",
    "\n",
    "# Assign partition labels: 0 for train, 1 for validation. 2 for test\n",
    "train_df['partition'] = 0\n",
    "val_df['partition'] = 1\n",
    "test_df['partition'] = 2\n",
    "\n",
    "# Combine back to a single dataframe\n",
    "partitioned_df = pd.concat([train_df, val_df, test_df])\n",
    "\n",
    "PARTITION_OUTPUT_PATH = os.path.join(CELEBA_DATA_PATH,\"partitioned.csv\")\n",
    "\n",
    "# Export the partition data to a new CSV file\n",
    "try:\n",
    "    print(PARTITION_OUTPUT_PATH)\n",
    "    partitioned_df.to_csv(PARTITION_OUTPUT_PATH, index=False)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "# The 'partitioned.csv' file will now have the image_id, Gender, Age, and partition columns\n",
    "partitioned_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f89bda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, models\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "# Define a custom dataset\n",
    "class CelebADataset(Dataset):\n",
    "    def __init__(self, dataframe, img_dir, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.img_dir, self.dataframe.iloc[idx, 0])\n",
    "        image = Image.open(img_name)\n",
    "\n",
    "        # 'Gender' column is the second column \n",
    "        label = self.dataframe.iloc[idx, 1]\n",
    "\n",
    "        # Convert label to tensor\n",
    "        label = torch.tensor(label, dtype=torch.float32)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "\n",
    "# Load the partitioned dataset\n",
    "df = pd.read_csv(PARTITION_OUTPUT_PATH)\n",
    "\n",
    "# Assign binary labels to the 'Gender' column\n",
    "df['Gender'] = df['Gender'].map({'Male': 1, 'Female': 0})\n",
    "\n",
    "# Split the dataframe into training and validation sets\n",
    "train_df = df[df['partition'] == 0]\n",
    "val_df = df[df['partition'] == 1]\n",
    "test_df = df[df['partition'] == 2]\n",
    "\n",
    "# Define the transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# Function to create a data loader given the image paths\n",
    "def create_data_loader(df, img_dir, transform, batch_size=32):\n",
    "    dataset = CelebADataset(dataframe=df, img_dir=img_dir, transform=transform)\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    return loader\n",
    "    \n",
    "# Creating loaders\n",
    "train_loader = create_data_loader(train_df, IMG_PATH, transform)\n",
    "val_loader = create_data_loader(val_df, IMG_PATH, transform)\n",
    "test_loader = create_data_loader(test_df, IMG_PATH, transform)\n",
    "\n",
    "cropped_train_loader = create_data_loader(train_df, CROPPED_IMG_PATH, transform)\n",
    "cropped_val_loader = create_data_loader(val_df, CROPPED_IMG_PATH, transform)\n",
    "cropped_test_loader = create_data_loader(test_df, CROPPED_IMG_PATH, transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60779045",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the CNN model\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 28 * 28, 512)\n",
    "        self.fc2 = nn.Linear(512, 1) \n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(nn.functional.relu(self.conv1(x)))\n",
    "        x = self.pool(nn.functional.relu(self.conv2(x)))\n",
    "        x = self.pool(nn.functional.relu(self.conv3(x)))\n",
    "        x = x.view(-1, 64 * 28 * 28)  # Flatten the layer\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a59dba67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm import tqdm\n",
    "\n",
    "class EarlyStopping:\n",
    "    #Early stops the training if validation loss doesn't improve after a given patience.\n",
    "    def __init__(self, patience=5, verbose=False, delta=0, checkpoint_name=\"checkpoint.pt\"):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = float('inf')\n",
    "        self.delta = delta\n",
    "        self.checkpoint_name = checkpoint_name \n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        #Saves model when validation loss decreases.\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...')\n",
    "        torch.save(model.state_dict(), self.checkpoint_name) \n",
    "        self.val_loss_min = val_loss\n",
    "\n",
    "        \n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, scheduler, num_epochs, device, checkpoint_name):\n",
    "    # Initialize early stopping\n",
    "    early_stopping = EarlyStopping(patience=5, verbose=True, checkpoint_name=checkpoint_name)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        train_pbar = tqdm(train_loader, unit=\"batch\")\n",
    "        for inputs, labels in train_pbar:\n",
    "            train_pbar.set_description(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "            inputs, labels = inputs.to(device), labels.to(device).float()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels.view(-1, 1))  \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            train_pbar.set_postfix(loss=loss.item())\n",
    "\n",
    "        train_loss = running_loss / len(train_loader.dataset)\n",
    "\n",
    "        model.eval()\n",
    "        val_running_loss = 0.0\n",
    "        val_pbar = tqdm(val_loader, unit=\"batch\")\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_pbar:\n",
    "                val_pbar.set_description(f\"Val Epoch {epoch+1}/{num_epochs}\")\n",
    "                inputs, labels = inputs.to(device), labels.to(device).float()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels.view(-1, 1))  \n",
    "                val_running_loss += loss.item() * inputs.size(0)\n",
    "                val_pbar.set_postfix(loss=loss.item())\n",
    "\n",
    "        val_loss = val_running_loss / len(val_loader.dataset)\n",
    "        print(f'Epoch {epoch+1}/{num_epochs} Train loss: {train_loss:.4f} Val loss: {val_loss:.4f}')\n",
    "\n",
    "        # Call early stopping\n",
    "        early_stopping(val_loss, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping\")\n",
    "            break\n",
    "\n",
    "        scheduler.step(val_loss)\n",
    "\n",
    "    # Load the last checkpoint with the best model\n",
    "    model.load_state_dict(torch.load(checkpoint_name))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c7de9c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: 100%|████████████████████████████████████████████████████| 1250/1250 [01:36<00:00, 12.92batch/s, loss=0.24]\n",
      "Val Epoch 1/50: 100%|██████████████████████████████████████████████████| 157/157 [00:14<00:00, 10.57batch/s, loss=0.32]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 Train loss: 0.2361 Val loss: 0.1251\n",
      "Validation loss decreased (inf --> 0.125149).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50: 100%|██████████████████████████████████████████████████| 1250/1250 [01:02<00:00, 20.13batch/s, loss=0.0966]\n",
      "Val Epoch 2/50: 100%|██████████████████████████████████████████████| 157/157 [00:06<00:00, 23.86batch/s, loss=0.000314]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50 Train loss: 0.1105 Val loss: 0.1075\n",
      "Validation loss decreased (0.125149 --> 0.107541).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/50: 100%|██████████████████████████████████████████████████| 1250/1250 [01:02<00:00, 20.04batch/s, loss=0.0391]\n",
      "Val Epoch 3/50: 100%|███████████████████████████████████████████████| 157/157 [00:06<00:00, 23.83batch/s, loss=0.00089]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50 Train loss: 0.0810 Val loss: 0.1042\n",
      "Validation loss decreased (0.107541 --> 0.104248).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/50: 100%|██████████████████████████████████████████████████| 1250/1250 [01:02<00:00, 19.88batch/s, loss=0.0189]\n",
      "Val Epoch 4/50: 100%|██████████████████████████████████████████████| 157/157 [00:06<00:00, 23.38batch/s, loss=0.000844]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50 Train loss: 0.0596 Val loss: 0.1174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/50: 100%|█████████████████████████████████████████████████| 1250/1250 [01:02<00:00, 19.92batch/s, loss=0.00482]\n",
      "Val Epoch 5/50: 100%|█████████████████████████████████████████████████| 157/157 [00:06<00:00, 23.57batch/s, loss=0.344]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50 Train loss: 0.0435 Val loss: 0.1298\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/50: 100%|███████████████████████████████████████████████████| 1250/1250 [01:02<00:00, 19.89batch/s, loss=0.016]\n",
      "Val Epoch 6/50: 100%|████████████████████████████████████████████████| 157/157 [00:06<00:00, 23.73batch/s, loss=0.0132]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50 Train loss: 0.0351 Val loss: 0.1261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/50: 100%|█████████████████████████████████████████████████| 1250/1250 [01:02<00:00, 19.89batch/s, loss=0.00682]\n",
      "Val Epoch 7/50: 100%|███████████████████████████████████████████████| 157/157 [00:06<00:00, 22.95batch/s, loss=4.29e-6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50 Train loss: 0.0263 Val loss: 0.1695\n",
      "Epoch 00007: reducing learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/50: 100%|█████████████████████████████████████████████████| 1250/1250 [01:03<00:00, 19.61batch/s, loss=0.00225]\n",
      "Val Epoch 8/50: 100%|███████████████████████████████████████████████| 157/157 [00:06<00:00, 23.68batch/s, loss=0.00328]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50 Train loss: 0.0112 Val loss: 0.1533\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: 100%|███████████████████████████████████████████████████| 1250/1250 [00:55<00:00, 22.53batch/s, loss=0.217]\n",
      "Val Epoch 1/50: 100%|████████████████████████████████████████████████| 157/157 [00:05<00:00, 26.19batch/s, loss=0.0475]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 Train loss: 0.3470 Val loss: 0.2534\n",
      "Validation loss decreased (inf --> 0.253365).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50: 100%|███████████████████████████████████████████████████| 1250/1250 [00:51<00:00, 24.27batch/s, loss=0.263]\n",
      "Val Epoch 2/50: 100%|██████████████████████████████████████████████████| 157/157 [00:05<00:00, 28.14batch/s, loss=0.54]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50 Train loss: 0.2126 Val loss: 0.2104\n",
      "Validation loss decreased (0.253365 --> 0.210396).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/50: 100%|███████████████████████████████████████████████████| 1250/1250 [00:51<00:00, 24.36batch/s, loss=0.182]\n",
      "Val Epoch 3/50: 100%|█████████████████████████████████████████████████| 157/157 [00:05<00:00, 29.56batch/s, loss=0.177]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50 Train loss: 0.1585 Val loss: 0.1893\n",
      "Validation loss decreased (0.210396 --> 0.189337).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/50: 100%|████████████████████████████████████████████████████| 1250/1250 [00:51<00:00, 24.04batch/s, loss=0.17]\n",
      "Val Epoch 4/50: 100%|████████████████████████████████████████████████| 157/157 [00:05<00:00, 29.94batch/s, loss=0.0968]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50 Train loss: 0.1120 Val loss: 0.1850\n",
      "Validation loss decreased (0.189337 --> 0.185024).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/50: 100%|██████████████████████████████████████████████████| 1250/1250 [00:50<00:00, 24.85batch/s, loss=0.0635]\n",
      "Val Epoch 5/50: 100%|█████████████████████████████████████████████████| 157/157 [00:05<00:00, 28.76batch/s, loss=0.256]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50 Train loss: 0.0756 Val loss: 0.2300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/50: 100%|██████████████████████████████████████████████████| 1250/1250 [00:51<00:00, 24.41batch/s, loss=0.0335]\n",
      "Val Epoch 6/50: 100%|██████████████████████████████████████████████████| 157/157 [00:05<00:00, 28.95batch/s, loss=1.22]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50 Train loss: 0.0486 Val loss: 0.2472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/50: 100%|██████████████████████████████████████████████████| 1250/1250 [00:51<00:00, 24.15batch/s, loss=0.0698]\n",
      "Val Epoch 7/50: 100%|████████████████████████████████████████████████| 157/157 [00:05<00:00, 29.78batch/s, loss=0.0014]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50 Train loss: 0.0392 Val loss: 0.2748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/50: 100%|█████████████████████████████████████████████████| 1250/1250 [00:51<00:00, 24.35batch/s, loss=0.00481]\n",
      "Val Epoch 8/50: 100%|██████████████████████████████████████████████████| 157/157 [00:05<00:00, 29.87batch/s, loss=1.27]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50 Train loss: 0.0322 Val loss: 0.2947\n",
      "Epoch 00008: reducing learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/50: 100%|████████████████████████████████████████████████| 1250/1250 [00:51<00:00, 24.16batch/s, loss=0.000188]\n",
      "Val Epoch 9/50: 100%|█████████████████████████████████████████████████| 157/157 [00:05<00:00, 29.70batch/s, loss=0.343]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50 Train loss: 0.0109 Val loss: 0.3176\n",
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch import nn\n",
    "\n",
    "# For non-cropped images\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model_non_cropped = SimpleCNN().to(device)\n",
    "optimizer_non_cropped = torch.optim.Adam(model_non_cropped.parameters(), lr=0.001)\n",
    "scheduler_non_cropped = ReduceLROnPlateau(optimizer_non_cropped, 'min', patience=3, verbose=True)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "# For cropped images\n",
    "model_cropped = SimpleCNN().to(device)\n",
    "optimizer_cropped = torch.optim.Adam(model_cropped.parameters(), lr=0.001)\n",
    "scheduler_cropped = ReduceLROnPlateau(optimizer_cropped, 'min', patience=3, verbose=True)\n",
    "\n",
    "# Define the number of epochs\n",
    "num_epochs = 50\n",
    "\n",
    "# Call the training function for non-cropped images\n",
    "trained_model_non_cropped = train_model(\n",
    "    model_non_cropped,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    criterion,\n",
    "    optimizer_non_cropped,\n",
    "    scheduler_non_cropped,\n",
    "    num_epochs,\n",
    "    device,\n",
    "    checkpoint_name='model_non_cropped_checkpoint.pt'\n",
    ")\n",
    "\n",
    "# Call the training function for cropped images\n",
    "trained_model_cropped = train_model(\n",
    "    model_cropped,\n",
    "    cropped_train_loader,\n",
    "    cropped_val_loader,\n",
    "    criterion,\n",
    "    optimizer_cropped,\n",
    "    scheduler_cropped,\n",
    "    num_epochs,\n",
    "    device,\n",
    "    checkpoint_name='model_cropped_checkpoint.pt'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5052d717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uncropped model on Cropped Test Accuracy: 65.82%\n",
      "Uncropped model on Uncropped Test Accuracy: 96.24%\n",
      "Cropped model on Cropped Test Accuracy: 93.70%\n",
      "Cropped model on Uncropped Test Accuracy: 93.72%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def evaluate_model(model, test_loader, device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    with torch.no_grad(): \n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device).float()  \n",
    "            outputs = model(inputs)\n",
    "            \n",
    "            predictions = torch.sigmoid(outputs).round().cpu().numpy()\n",
    "            y_pred.extend(predictions)\n",
    "            y_true.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    return accuracy, y_true, y_pred\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"mps\")\n",
    "\n",
    "checkpoint = 'model_non_cropped_checkpoint.pt'  \n",
    "model = SimpleCNN().to(device)\n",
    "model.load_state_dict(torch.load(checkpoint))\n",
    "\n",
    "checkpoint = 'model_cropped_checkpoint.pt'  \n",
    "cropped_model = SimpleCNN().to(device)\n",
    "cropped_model.load_state_dict(torch.load(checkpoint))\n",
    "\n",
    "# test both against cropped and uncropped data\n",
    "accuracy, true_labels, predicted_labels = evaluate_model(model, cropped_test_loader, device)\n",
    "print(f\"Uncropped model on Cropped Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "accuracy, true_labels, predicted_labels = evaluate_model(model, test_loader, device)\n",
    "print(f\"Uncropped model on Uncropped Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "accuracy, true_labels, predicted_labels = evaluate_model(cropped_model, cropped_test_loader, device)\n",
    "print(f\"Cropped model on Cropped Test Accuracy: {accuracy * 100:.2f}%\")\n",
    "\n",
    "accuracy, true_labels, predicted_labels = evaluate_model(cropped_model, test_loader, device)\n",
    "print(f\"Cropped model on Uncropped Test Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09084b83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400eea4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611d676f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
